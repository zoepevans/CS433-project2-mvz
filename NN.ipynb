{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/zoe/Documents/EPFL/Ma3/ML/Project2/CS433-project2-mvz/data/features_2b.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m targets_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/energies.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Create dataset instance\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MyDataset( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-body\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[1;32m     65\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36mMyDataset.__init__\u001b[0;34m(self, feature_choice)\u001b[0m\n\u001b[1;32m      5\u001b[0m data_paths \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergies\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergies.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-body\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_2b.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-body\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_3b.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4-body\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_4b.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-body\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-body\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m feature_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-body\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     14\u001b[0m     features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-body\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/zoe/Documents/EPFL/Ma3/ML/Project2/CS433-project2-mvz/data/features_2b.npy'"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, feature_choice):\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        data_paths = {\n",
    "            \"energies\": os.path.join(\"..\", \"data\", \"energies.npy\"),\n",
    "            \"2-body\": os.path.join(\"..\", \"data\", \"features_2b.npy\"),\n",
    "            \"3-body\": os.path.join(\"..\", \"data\", \"features_3b.npy\"),\n",
    "            \"4-body\": os.path.join(\"..\", \"data\", \"features_4b.npy\"),\n",
    "            }\n",
    "        if feature_choice == \"2-body\":\n",
    "            features = np.load(data_paths[\"2-body\"])\n",
    "        elif feature_choice == \"3-body\":\n",
    "            features = np.load(data_paths[\"3-body\"])\n",
    "        elif feature_choice == \"4-body\":\n",
    "            features = np.load(data_paths[\"4-body\"])\n",
    "        elif feature_choice == \"2+3-body\":\n",
    "            features_2 = np.load(data_paths[\"2-body\"])\n",
    "            features_3 = np.load(data_paths[\"3-body\"])\n",
    "            features = np.hstack((features_2, features_3))\n",
    "        elif feature_choice == \"4+3-body\":\n",
    "            features_4 = np.load(data_paths[\"4-body\"])\n",
    "            features_3 = np.load(data_paths[\"3-body\"])\n",
    "            features = np.hstack((features_4, features_3))\n",
    "        elif feature_choice == \"2+3+4-body\":\n",
    "            features_2 = np.load(data_paths[\"2-body\"])\n",
    "            features_3 = np.load(data_paths[\"3-body\"])\n",
    "            features_4 = np.load(data_paths[\"4-body\"])\n",
    "            features = np.hstack((features_2, features_3, features_4))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid feature choice!\")\n",
    "\n",
    "        self.features = features\n",
    "        \n",
    "        self.targets = np.load(data_paths[\"energies\"])\n",
    "        \n",
    "        # Make sure both have the same length\n",
    "        assert len(self.features) == len(self.targets), \"Features and targets must have the same length\"\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve the features and target for the given index\n",
    "        feature_row = self.features.iloc[index].values  # Convert to numpy array\n",
    "        target_value = self.targets.iloc[index].values  # Convert to numpy array\n",
    "        \n",
    "        # Convert the features to a tensor\n",
    "        features = torch.tensor(feature_row, dtype=torch.float32)\n",
    "        \n",
    "        # Convert the target to a tensor\n",
    "        target = torch.tensor(target_value, dtype=torch.float32)\n",
    "        \n",
    "        return features, target\n",
    "\n",
    "# Paths to your CSV files\n",
    "features_file = '../data/features_2b.npy'\n",
    "targets_file = '../data/energies.npy'\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = MyDataset( \"2-body\")\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
